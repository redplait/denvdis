        .version ${PTX_MAJOR_VERSION}.${PTX_MINOR_VERSION}
        .target ${GPU_ARCH}
    .weak .func (.reg .f32 %fv1) __cuda_sm20_div_rz_f32 (.reg .f32 %fa1, .reg .f32 %fa2)
    {
        .reg .u32 %r<65>;
        .reg .f32 %f<25>;
        .reg .pred %p<18>;
    $LBB1___cuda_sm20_div_rz_f32_:
        mov.f32 %f1, %fa1;
        mov.f32 %f2, %fa2;
        mov.b32 %r1, %f1;
        mov.s32 %r2, %r1;
        mov.b32 %r3, %f2;
        mov.s32 %r4, %r3;
        shl.b32 %r5, %r1, 1;
        shr.u32 %r6, %r5, 24;
        sub.s32 %r7, %r6, 1;
        shl.b32 %r8, %r3, 1;
        shr.u32 %r9, %r8, 24;
        sub.s32 %r10, %r9, 1;
        mov.u32 %r11, 253;
        set.gt.u32.u32 %r12, %r10, %r11;
        neg.s32 %r13, %r12;
        mov.u32 %r14, 253;
        set.gt.u32.u32 %r15, %r7, %r14;
        neg.s32 %r16, %r15;
        or.b32 %r17, %r13, %r16;
        mov.u32 %r18, 0;
        setp.eq.s32 %p1, %r17, %r18;
        @%p1 bra $Lt_4_10242;
        abs.ftz.f32 %f3, %f1;
        mov.f32 %f4, 0f7f800000;
        setp.le.ftz.f32 %p2, %f3, %f4;
        @!%p2 bra $Lt_4_258;
        abs.ftz.f32 %f5, %f2;
        mov.f32 %f6, 0f7f800000;
        setp.le.ftz.f32 %p3, %f5, %f6;
        @%p3 bra $Lt_4_514;
    $Lt_4_258:
        add.ftz.f32 %fv1, %f1, %f2;
        bra.uni $LBB30___cuda_sm20_div_rz_f32_;
    $Lt_4_514:
        shl.b32 %r19, %r1, 1;
        shl.b32 %r20, %r3, 1;
        mov.u32 %r21, 0;
        setp.eq.u32 %p4, %r19, %r21;
        mov.u32 %r22, 0;
        setp.eq.u32 %p5, %r20, %r22;
        selp.s32 %r23, 1, 0, %p4;
        selp.s32 %r24, 1, 0, %p5;
        and.b32 %r25, %r23, %r24;
        mov.u32 %r26, 0;
        setp.ne.s32 %p6, %r25, %r26;
        @%p6 bra $Lt_4_1026;
        mov.f32 %f7, 0f7f800000;
        setp.eq.ftz.f32 %p7, %f3, %f7;
        mov.f32 %f8, 0f7f800000;
        setp.eq.ftz.f32 %p8, %f5, %f8;
        @!%p7 bra $Lt_4_15106;
        @!%p8 bra $Lt_4_15106;
    $Lt_4_1026:
        mov.f32 %f9, 0fffc00000;
        rsqrt.approx.ftz.f32 %fv1, %f9;
        bra.uni $LBB30___cuda_sm20_div_rz_f32_;
    $Lt_4_15106:
    $Lt_4_1282:
        selp.s32 %r27, 1, 0, %p8;
        or.b32 %r28, %r27, %r23;
        mov.u32 %r29, 0;
        setp.eq.s32 %p9, %r28, %r29;
        @%p9 bra $Lt_4_10498;
        xor.b32 %r30, %r3, %r1;
        and.b32 %r31, %r30, -2147483648;
        mov.b32 %fv1, %r31;
        bra.uni $LBB30___cuda_sm20_div_rz_f32_;
    $Lt_4_10498:
        selp.s32 %r32, 1, 0, %p7;
        or.b32 %r33, %r32, %r24;
        mov.u32 %r34, 0;
        setp.eq.s32 %p10, %r33, %r34;
        @%p10 bra $Lt_4_11010;
        xor.b32 %r35, %r3, %r1;
        and.b32 %r36, %r35, -2147483648;
        or.b32 %r37, %r36, 2139095040;
        mov.b32 %fv1, %r37;
        bra.uni $LBB30___cuda_sm20_div_rz_f32_;
    $Lt_4_11010:
        mov.u32 %r38, 0;
        setp.ge.s32 %p11, %r7, %r38;
        @%p11 bra $Lt_4_11778;
        mov.f32 %f10, 0f5f800000;
        mov.f32 %f11, 0f00000000;
        fma.rn.f32 %f1, %f1, %f10, %f11;
        mov.b32 %r2, %f1;
        mov.s32 %r39, -64;
        bra.uni $Lt_4_11522;
    $Lt_4_11778:
        mov.s32 %r39, 0;
    $Lt_4_11522:
        mov.u32 %r40, 0;
        setp.ge.s32 %p12, %r10, %r40;
        @%p12 bra $Lt_4_9986;
        mov.f32 %f12, 0f5f800000;
        mov.f32 %f13, 0f00000000;
        fma.rn.f32 %f2, %f2, %f12, %f13;
        mov.b32 %r4, %f2;
        add.s32 %r39, %r39, 64;
        bra.uni $Lt_4_9986;
    $Lt_4_10242:
        mov.s32 %r39, 0;
    $Lt_4_9986:
        sub.s32 %r41, %r7, 126;
        shl.b32 %r42, %r41, 23;
        sub.u32 %r2, %r2, %r42;
        sub.s32 %r43, %r10, 126;
        shl.b32 %r44, %r43, 23;
        sub.u32 %r4, %r4, %r44;
        mov.b32 %f14, %r4;
        mov.b32 %f15, %r2;
        neg.ftz.f32 %f16, %f14;
        rcp.approx.ftz.f32 %f17, %f14;
        mov.f32 %f18, 0f00000000;
        fma.rn.f32 %f19, %f15, %f17, %f18;
        fma.rn.f32 %f20, %f16, %f19, %f15;
        fma.rn.f32 %f21, %f20, %f17, %f19;
        fma.rn.f32 %f22, %f16, %f21, %f15;
        fma.rz.f32 %f23, %f22, %f17, %f21;
        mov.b32 %r45, %f23;
        mov.s32 %r46, %r45;
        sub.s32 %r47, %r7, %r10;
        shl.b32 %r48, %r45, 1;
        shr.u32 %r49, %r48, 24;
        add.u32 %r50, %r47, %r49;
        add.u32 %r51, %r39, %r50;
        sub.u32 %r52, %r51, 1;
        mov.u32 %r53, 253;
        setp.gt.u32 %p13, %r52, %r53;
        @%p13 bra $Lt_4_12802;
        sub.u32 %r54, %r51, %r49;
        shl.b32 %r55, %r54, 23;
        add.u32 %r46, %r45, %r55;
        mov.b32 %f23, %r46;
        bra.uni $Lt_4_12546;
    $Lt_4_12802:
        mov.u32 %r56, 254;
        setp.le.s32 %p14, %r51, %r56;
        @%p14 bra $Lt_4_13314;
        mov.u32 %r46, 2139095039;
        bra.uni $Lt_4_14082;
    $Lt_4_13314:
        mov.u32 %r57, 0;
        setp.gt.s32 %p15, %r51, %r57;
        @%p15 bra $Lt_4_14082;
        mov.u32 %r58, -24;
        setp.ge.s32 %p16, %r51, %r58;
        @%p16 bra $Lt_4_14338;
        mov.u32 %r46, 0;
        bra.uni $Lt_4_14082;
    $Lt_4_14338:
        and.b32 %r59, %r45, 8388607;
        or.b32 %r60, %r59, 8388608;
        mov.s32 %r61, 1;
        sub.s32 %r62, %r61, %r51;
        shr.u32 %r46, %r60, %r62;
    $Lt_4_14082:
    $Lt_4_13570:
    $Lt_4_13058:
        and.b32 %r63, %r45, -2147483648;
        or.b32 %r46, %r46, %r63;
        mov.b32 %f23, %r46;
    $Lt_4_12546:
        mov.f32 %fv1, %f23;
    $LBB30___cuda_sm20_div_rz_f32_:
        ret;
    }
