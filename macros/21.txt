        .version ${PTX_MAJOR_VERSION}.${PTX_MINOR_VERSION}
        .target ${GPU_ARCH}
    .weak .func (.reg .f32 %fv1) __cuda_sm20_div_ru_f32 (.reg .f32 %fa1, .reg .f32 %fa2)
    {
        .reg .u32 %r<87>;
        .reg .f32 %f<27>;
        .reg .pred %p<20>;
    $LBB1___cuda_sm20_div_ru_f32_:
        mov.f32 %f1, %fa1;
        mov.f32 %f2, %fa2;
        mov.b32 %r1, %f1;
        mov.s32 %r2, %r1;
        mov.b32 %r3, %f2;
        mov.s32 %r4, %r3;
        shl.b32 %r5, %r1, 1;
        shr.u32 %r6, %r5, 24;
        sub.s32 %r7, %r6, 1;
        shl.b32 %r8, %r3, 1;
        shr.u32 %r9, %r8, 24;
        sub.s32 %r10, %r9, 1;
        mov.u32 %r11, 253;
        set.gt.u32.u32 %r12, %r10, %r11;
        neg.s32 %r13, %r12;
        mov.u32 %r14, 253;
        set.gt.u32.u32 %r15, %r7, %r14;
        neg.s32 %r16, %r15;
        or.b32 %r17, %r13, %r16;
        mov.u32 %r18, 0;
        setp.eq.s32 %p1, %r17, %r18;
        @%p1 bra $Lt_5_14082;
        abs.ftz.f32 %f3, %f1;
        mov.f32 %f4, 0f7f800000;
        setp.le.ftz.f32 %p2, %f3, %f4;
        @!%p2 bra $Lt_5_258;
        abs.ftz.f32 %f5, %f2;
        mov.f32 %f6, 0f7f800000;
        setp.le.ftz.f32 %p3, %f5, %f6;
        @%p3 bra $Lt_5_514;
    $Lt_5_258:
        add.ftz.f32 %fv1, %f1, %f2;
        bra.uni $LBB32___cuda_sm20_div_ru_f32_;
    $Lt_5_514:
        shl.b32 %r19, %r1, 1;
        shl.b32 %r20, %r3, 1;
        mov.u32 %r21, 0;
        setp.eq.u32 %p4, %r19, %r21;
        mov.u32 %r22, 0;
        setp.eq.u32 %p5, %r20, %r22;
        selp.s32 %r23, 1, 0, %p4;
        selp.s32 %r24, 1, 0, %p5;
        and.b32 %r25, %r23, %r24;
        mov.u32 %r26, 0;
        setp.ne.s32 %p6, %r25, %r26;
        @%p6 bra $Lt_5_1026;
        mov.f32 %f7, 0f7f800000;
        setp.eq.ftz.f32 %p7, %f3, %f7;
        mov.f32 %f8, 0f7f800000;
        setp.eq.ftz.f32 %p8, %f5, %f8;
        @!%p7 bra $Lt_5_19458;
        @!%p8 bra $Lt_5_19458;
    $Lt_5_1026:
        mov.f32 %f9, 0fffc00000;
        rsqrt.approx.ftz.f32 %fv1, %f9;
        bra.uni $LBB32___cuda_sm20_div_ru_f32_;
    $Lt_5_19458:
    $Lt_5_1282:
        selp.s32 %r27, 1, 0, %p8;
        or.b32 %r28, %r27, %r23;
        mov.u32 %r29, 0;
        setp.eq.s32 %p9, %r28, %r29;
        @%p9 bra $Lt_5_14338;
        xor.b32 %r30, %r3, %r1;
        and.b32 %r31, %r30, -2147483648;
        mov.b32 %fv1, %r31;
        bra.uni $LBB32___cuda_sm20_div_ru_f32_;
    $Lt_5_14338:
        selp.s32 %r32, 1, 0, %p7;
        or.b32 %r33, %r32, %r24;
        mov.u32 %r34, 0;
        setp.eq.s32 %p10, %r33, %r34;
        @%p10 bra $Lt_5_14850;
        xor.b32 %r35, %r3, %r1;
        and.b32 %r36, %r35, -2147483648;
        or.b32 %r37, %r36, 2139095040;
        mov.b32 %fv1, %r37;
        bra.uni $LBB32___cuda_sm20_div_ru_f32_;
    $Lt_5_14850:
        mov.u32 %r38, 0;
        setp.ge.s32 %p11, %r7, %r38;
        @%p11 bra $Lt_5_15618;
        mov.f32 %f10, 0f5f800000;
        mov.f32 %f11, 0f00000000;
        fma.rn.f32 %f1, %f1, %f10, %f11;
        mov.b32 %r2, %f1;
        mov.s32 %r39, -64;
        bra.uni $Lt_5_15362;
    $Lt_5_15618:
        mov.s32 %r39, 0;
    $Lt_5_15362:
        mov.u32 %r40, 0;
        setp.ge.s32 %p12, %r10, %r40;
        @%p12 bra $Lt_5_13826;
        mov.f32 %f12, 0f5f800000;
        mov.f32 %f13, 0f00000000;
        fma.rn.f32 %f2, %f2, %f12, %f13;
        mov.b32 %r4, %f2;
        add.s32 %r39, %r39, 64;
        bra.uni $Lt_5_13826;
    $Lt_5_14082:
        mov.s32 %r39, 0;
    $Lt_5_13826:
        sub.s32 %r41, %r7, 126;
        shl.b32 %r42, %r41, 23;
        sub.u32 %r2, %r2, %r42;
        sub.s32 %r43, %r10, 126;
        shl.b32 %r44, %r43, 23;
        sub.u32 %r4, %r4, %r44;
        mov.b32 %f14, %r4;
        mov.b32 %f15, %r2;
        neg.ftz.f32 %f16, %f14;
        rcp.approx.ftz.f32 %f17, %f14;
        mov.f32 %f18, 0f00000000;
        fma.rn.f32 %f19, %f15, %f17, %f18;
        fma.rn.f32 %f20, %f16, %f19, %f15;
        fma.rn.f32 %f21, %f20, %f17, %f19;
        fma.rn.f32 %f22, %f16, %f21, %f15;
        fma.rp.f32 %f23, %f22, %f17, %f21;
        mov.b32 %r45, %f23;
        mov.s32 %r46, %r45;
        sub.s32 %r47, %r7, %r10;
        shl.b32 %r48, %r45, 1;
        shr.u32 %r49, %r48, 24;
        add.u32 %r50, %r47, %r49;
        add.u32 %r51, %r39, %r50;
        sub.u32 %r52, %r51, 1;
        mov.u32 %r53, 253;
        setp.gt.u32 %p13, %r52, %r53;
        @%p13 bra $Lt_5_16642;
        sub.u32 %r54, %r51, %r49;
        shl.b32 %r55, %r54, 23;
        add.u32 %r46, %r45, %r55;
        bra.uni $Lt_5_16386;
    $Lt_5_16642:
        and.b32 %r56, %r45, -2147483648;
        mov.u32 %r57, 254;
        setp.le.s32 %p14, %r51, %r57;
        @%p14 bra $Lt_5_17154;
        mov.u32 %r58, 2139095040;
        mov.u32 %r59, 2139095039;
        mov.s32 %r60, 0;
        setp.eq.s32 %p15, %r56, %r60;
        selp.u32 %r46, %r58, %r59, %p15;
        bra.uni $Lt_5_17922;
    $Lt_5_17154:
        mov.u32 %r61, 0;
        setp.gt.s32 %p16, %r51, %r61;
        @%p16 bra $Lt_5_17922;
        mov.u32 %r62, -24;
        setp.ge.s32 %p17, %r51, %r62;
        @%p17 bra $Lt_5_18178;
        mov.s32 %r63, 0;
        set.eq.u32.s32 %r64, %r56, %r63;
        neg.s32 %r46, %r64;
        bra.uni $Lt_5_17922;
    $Lt_5_18178:
        fma.rm.f32 %f24, %f22, %f17, %f21;
        set.neu.ftz.u32.f32 %r65, %f23, %f24;
        neg.s32 %r66, %r65;
        fma.rz.f32 %f25, %f22, %f17, %f21;
        mov.b32 %r67, %f25;
        and.b32 %r68, %r67, 8388607;
        or.b32 %r46, %r68, 8388608;
        mov.u32 %r69, 1;
        setp.eq.s32 %p18, %r51, %r69;
        @%p18 bra $Lt_5_18434;
        add.s32 %r70, %r51, 31;
        shl.b32 %r71, %r46, %r70;
        mov.u32 %r72, 0;
        set.ne.u32.u32 %r73, %r71, %r72;
        neg.s32 %r74, %r73;
        or.b32 %r66, %r66, %r74;
        mov.s32 %r75, 1;
        sub.s32 %r76, %r75, %r51;
        shr.u32 %r46, %r46, %r76;
    $Lt_5_18434:
        add.u32 %r77, %r46, 1;
        mov.s32 %r78, 0;
        set.eq.u32.s32 %r79, %r56, %r78;
        neg.s32 %r80, %r79;
        mov.s32 %r81, 0;
        set.ne.u32.s32 %r82, %r66, %r81;
        neg.s32 %r83, %r82;
        and.b32 %r84, %r80, %r83;
        neg.s32 %r85, %r84;
        slct.u32.s32 %r46, %r46, %r77, %r85;
    $Lt_5_17922:
    $Lt_5_17410:
    $Lt_5_16898:
        or.b32 %r46, %r56, %r46;
    $Lt_5_16386:
        mov.b32 %fv1, %r46;
    $LBB32___cuda_sm20_div_ru_f32_:
        ret;
    }
