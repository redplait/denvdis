        .version ${PTX_MAJOR_VERSION}.${PTX_MINOR_VERSION}
        .target ${GPU_ARCH}
    .weak .func (.reg .f32 %fv1) __cuda_sm3x_div_rn_noftz_f32_slowpath (.reg .f32 %fa1, .reg .f32 %fa2)
    {
    .reg .f32 %f<40>;
    .reg .pred %p<27>;
    .reg .s32 %r<71>;
    mov.f32 %f1, %fa1;
    mov.f32 %f2, %fa2;
    mov.b32 %r67, %f1;
    shr.u32 %r23, %r67, 23;
    and.b32 %r2, %r23, 255;
    add.s32 %r3, %r2, -1;
    mov.b32 %r68, %f2;
    shr.u32 %r24, %r68, 23;
    and.b32 %r5, %r24, 255;
    add.s32 %r6, %r5, -1;
    setp.gt.u32 %p2, %r3, 253;
    setp.gt.u32 %p3, %r6, 253;
    or.pred %p4, %p2, %p3;
    @%p4 bra BB0_2;
    mov.u32 %r69, 0;
    bra.uni BB0_13;
BB0_2:
    mov.f32 %f36, %fa1;
    abs.ftz.f32 %f3, %f36;
    mov.u32 %r26, 2139095040;
    mov.b32 %f4, %r26;
    setp.gtu.ftz.f32 %p5, %f3, %f4;
    @%p5 bra BB0_24;
    mov.f32 %f39, %fa2;
    abs.ftz.f32 %f5, %f39;
    setp.gtu.ftz.f32 %p6, %f5, %f4;
    @%p6 bra BB0_24;
    or.b32 %r27, %r68, %r67;
    and.b32 %r28, %r27, 2147483647;
    setp.eq.s32 %p7, %r28, 0;
    @%p7 bra BB0_23;
    setp.eq.ftz.f32 %p1, %f3, %f4;
    setp.eq.ftz.f32 %p8, %f5, %f4;
    and.pred %p9, %p1, %p8;
    @%p9 bra BB0_23;
    and.b32 %r29, %r67, 2147483647;
    setp.eq.s32 %p11, %r29, 0;
    or.pred %p12, %p8, %p11;
    @%p12 bra BB0_22;
    and.b32 %r30, %r68, 2147483647;
    setp.eq.s32 %p13, %r30, 0;
    or.pred %p14, %p1, %p13;
    @%p14 bra BB0_21;
    setp.lt.s32 %p15, %r3, 0;
    @%p15 bra BB0_10;
    mov.u32 %r69, 0;
    bra.uni BB0_11;
BB0_10:
    mov.f32 %f9, 0f00000000;
    mov.f32 %f10, 0f5F800000;
    mov.f32 %f35, %fa1;
    fma.rn.f32 %f11, %f35, %f10, %f9;
    mov.b32 %r67, %f11;
    mov.u32 %r69, -64;
BB0_11:
    setp.lt.s32 %p16, %r6, 0;
    @%p16 bra BB0_12;
    bra.uni BB0_13;
BB0_12:
    mov.f32 %f12, 0f00000000;
    mov.f32 %f13, 0f5F800000;
    mov.f32 %f38, %fa2;
    fma.rn.f32 %f14, %f38, %f13, %f12;
    mov.b32 %r68, %f14;
    add.s32 %r69, %r69, 64;
BB0_13:
    add.s32 %r33, %r2, -127;
    shl.b32 %r34, %r33, 23;
    sub.s32 %r35, %r67, %r34;
    mov.b32 %f17, %r35;
    shl.b32 %r36, %r5, 23;
    add.s32 %r37, %r36, -1065353216;
    sub.s32 %r38, %r68, %r37;
    mov.b32 %f16, %r38;
    rcp.ftz.approx.f32 %f15,%f16;
    neg.ftz.f32 %f18, %f16;
    mov.f32 %f19, 0f3F800000;
    fma.rn.f32 %f20, %f18, %f15, %f19;
    fma.rn.f32 %f6, %f15, %f20, %f15;
    mov.f32 %f21, 0f00000000;
    fma.rn.f32 %f22, %f17, %f6, %f21;
    fma.rn.f32 %f23, %f18, %f22, %f17;
    fma.rn.f32 %f7, %f23, %f6, %f22;
    fma.rn.f32 %f8, %f18, %f7, %f17;
    fma.rn.f32 %f24, %f8, %f6, %f7;
    mov.b32 %r70, %f24;
    shr.u32 %r39, %r70, 23;
    and.b32 %r40, %r39, 255;
    mov.u32 %r41, 127;
    sub.s32 %r42, %r41, %r5;
    add.s32 %r43, %r42, %r33;
    add.s32 %r16, %r43, %r69;
    add.s32 %r17, %r16, %r40;
    add.s32 %r44, %r17, -1;
    setp.lt.u32 %p17, %r44, 254;
    @%p17 bra BB0_19;
    setp.gt.s32 %p18, %r17, 254;
    @%p18 bra BB0_18;
    setp.lt.s32 %p19, %r17, 1;
    @%p19 bra BB0_16;
    bra.uni BB0_20;
BB0_16:
    setp.lt.s32 %p20, %r17, -24;
    and.b32 %r70, %r70, -2147483648;
    @%p20 bra BB0_20;
    fma.rp.f32 %f25, %f8, %f6, %f7;
    fma.rm.f32 %f26, %f8, %f6, %f7;
    setp.neu.ftz.f32 %p21, %f25, %f26;
    fma.rz.f32 %f27, %f8, %f6, %f7;
    mov.b32 %r45, %f27;
    and.b32 %r46, %r45, 8388607;
    or.b32 %r47, %r46, 8388608;
    add.s32 %r48, %r17, 32;
    shl.b32 %r49, %r47, %r48;
    setp.ne.s32 %p22, %r49, 0;
    setp.eq.s32 %p23, %r17, 0;
    neg.s32 %r50, %r17;
    selp.b32 %r51, 0, %r50, %p23;
    shr.u32 %r52, %r47, %r51;
    setp.ne.s32 %p24, %r17, 0;
    and.pred %p25, %p22, %p24;
    or.pred %p26, %p21, %p25;
    selp.u32 %r53, 1, 0, %p26;
    shr.u32 %r54, %r52, 1;
    and.b32 %r55, %r54, 1;
    or.b32 %r56, %r53, %r55;
    and.b32 %r57, %r56, %r52;
    add.s32 %r58, %r57, %r54;
    or.b32 %r70, %r58, %r70;
    bra.uni BB0_20;
BB0_18:
    and.b32 %r59, %r70, -2147483648;
    or.b32 %r70, %r59, 2139095040;
    bra.uni BB0_20;
BB0_19:
    shl.b32 %r60, %r16, 23;
    add.s32 %r70, %r60, %r70;
BB0_20:
    mov.b32 %f28, %r70;
    mov.f32 %fv1, %f28;
    ret;
BB0_21:
    xor.b32 %r61, %r68, %r67;
    and.b32 %r62, %r61, -2147483648;
    or.b32 %r63, %r62, 2139095040;
    mov.b32 %f29, %r63;
    mov.f32 %fv1, %f29;
    ret;
BB0_22:
    xor.b32 %r64, %r68, %r67;
    and.b32 %r65, %r64, -2147483648;
    mov.b32 %f30, %r65;
    mov.f32 %fv1, %f30;
    ret;
BB0_23:
    mov.u32 %r66, -4194304;
    mov.b32 %f31, %r66;
    rsqrt.approx.ftz.f32 %f32, %f31;
    mov.f32 %fv1, %f32;
    ret;
BB0_24:
    mov.f32 %f34, %fa1;
    mov.f32 %f37, %fa2;
    add.ftz.f32 %f33, %f34, %f37;
    mov.f32 %fv1, %f33;
    ret;
    }
